{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80e1d492",
   "metadata": {},
   "source": [
    "LIF neuron : $U[t+1]=\\beta U[t] + WX[t+1]-R[t]$  \n",
    "input synaptic : $I_{in}[t] = WX[t]$  \n",
    "input spike : $X[t]$  \n",
    "output spike : $S[t]$  \n",
    "$\\beta$ : both hyperparameter & learnable parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670d3090",
   "metadata": {},
   "source": [
    "training networks : loss with weights  \n",
    "$\\frac{\\partial L}{\\partial W} = \\frac{\\partial L}{\\partial S[t]} \\frac{\\partial S[t]}{\\partial U[t]} \\frac{\\partial U[t]}{\\partial I[t]} \\frac{\\partial I[t]}{\\partial W}$  \n",
    "$\\frac{\\partial S[t]}{\\partial U[t]}=\\{0, \\infty\\}$ => dead neuron probelm => surrogate function  \n",
    "forward propagation은 같게 backpropagation=$\\frac{\\partial \\tilde{S}}{\\partial U} = \\frac{1}{\\pi} \\frac{1}{(1+[U\\pi]^2)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6c27365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snntorch as snn\n",
    "from snntorch import spikeplot as splt\n",
    "from snntorch import spikegen\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01d0c996",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeakySurrogate(nn.Module):\n",
    "    def __init__(self, beta, threshold=1.0):\n",
    "        super(LeakySurrogate, self).__init__()\n",
    "\n",
    "        self.beta = beta\n",
    "        self.threshold = threshold\n",
    "        self.spike_gradient = self.ATan.apply\n",
    "\n",
    "    def forward(self, input_, mem):\n",
    "        spk = self.spike_gradient(mem - self.threshold) # call heaviside\n",
    "        reset = (self.beta*spk*self.threshold).detach()\n",
    "        mem = self.beta*mem + input_ - reset\n",
    "        return spk, mem\n",
    "    \n",
    "    @staticmethod  # 데코레이터 -> self 안씀\n",
    "    class ATan(torch.autograd.Function):\n",
    "        @staticmethod\n",
    "        def forward(ctx, mem): # heaviside funtion\n",
    "            spk = (mem > 0).float() # mem-threshold>0 -> return 1\n",
    "            ctx.save_for_backward(mem) # forward 계산한 mem 저장\n",
    "            return spk\n",
    "\n",
    "        @staticmethod\n",
    "        def backward(ctx, grad_output):\n",
    "            (mem, )=ctx.saved_tensors\n",
    "            grad = 1/ (1+(np.pi*mem).pow_(2))\n",
    "            return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28ea4995",
   "metadata": {},
   "outputs": [],
   "source": [
    "lif1 = LeakySurrogate(beta=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8aa4c796",
   "metadata": {},
   "outputs": [],
   "source": [
    "lif1 = snn.Leaky(beta=0.9) # 구현되어있다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307c9106",
   "metadata": {},
   "source": [
    "사실 backpropagation은 모든 시간을 고려해야한다. 전의 loss의 sum과 지금의 loss를 더해야한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd774df",
   "metadata": {},
   "source": [
    "### setting decoding\n",
    "rate coding : 정답인 label이 평균 firing이 가장 높게  \n",
    "=> 정답의 U를 높게, 오답의 U는 낮게(weight 조절)  \n",
    "** 결과는 spike로 판단하지만 계산과정에서 U(막전위)를 쓰겠다(연속값이라 계산 easy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65818ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "batch_size = 128\n",
    "data_path='/tmp/data/mnist'\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35d1eb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28,28)),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0,), (1,))\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "659a84ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2026-02-10 04:38:33--  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
      "Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n",
      "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://www.di.ens.fr/~lelarge/MNIST.tar.gz [following]\n",
      "--2026-02-10 04:38:34--  https://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
      "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/x-gzip]\n",
      "Saving to: ‘MNIST.tar.gz.2’\n",
      "\n",
      "MNIST.tar.gz.2          [    <=>             ]  33.20M   236KB/s    in 5m 27s  \n",
      "\n",
      "2026-02-10 04:44:02 (104 KB/s) - ‘MNIST.tar.gz.2’ saved [34813078]\n",
      "\n",
      "MNIST/\n",
      "MNIST/raw/\n",
      "MNIST/raw/train-labels-idx1-ubyte\n",
      "MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "MNIST/raw/t10k-labels-idx1-ubyte\n",
      "MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "MNIST/raw/train-images-idx3-ubyte\n",
      "MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "MNIST/raw/t10k-images-idx3-ubyte\n",
      "MNIST/raw/train-images-idx3-ubyte.gz\n",
      "MNIST/processed/\n",
      "MNIST/processed/training.pt\n",
      "MNIST/processed/test.pt\n"
     ]
    }
   ],
   "source": [
    "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
    "!tar -zxvf MNIST.tar.gz\n",
    "\n",
    "mnist_train = datasets.MNIST(root = './', train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(root = './', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a3c35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False, drop_last=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac2fdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network\n",
    "num_inputs = 28*28\n",
    "num_hidden = 1000\n",
    "num_outputs = 10\n",
    "\n",
    "num_steps = 25\n",
    "beta = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a15856",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.lif1 = snn.Leaky(beta=beta)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
    "        self.lif2 = snn.Leaky(beta=beta)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "\n",
    "        spk2_rec = []\n",
    "        mem2_rec = []\n",
    "        \n",
    "        for step in range(num_steps):\n",
    "            cur1 = self.fc1(x)\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk2_rec.append(spk2)\n",
    "            mem2_rec.append(mem2)\n",
    "\n",
    "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n",
    "\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1016ac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "def print_batch_accuracy(data, targets, train=False):\n",
    "    output, _ = net(data.view(batch_size, -1)) # output : spike 기록, _ : mem\n",
    "    # _ : 알 필요 없는 정보를 이렇게 전달한다. 메모리 절약\n",
    "    _, idx = output.sum(dim=0).max(1) # max(1) 한 행에서 가장 큰 클래스(값 아니고 인덱스) 찾아 저장\n",
    "    acc = np.mean((targets == idx).detach().cpu().numpy())\n",
    "\n",
    "    if train:\n",
    "        print(f'Train set accuracy for a single minibatch: {acc*100:.2f}')\n",
    "\n",
    "    else:\n",
    "        print(f'Test set accuracy for a single minibatch: {acc*100:.2f}')\n",
    "\n",
    "def train_printer(\n",
    "        data, targets, epoch, counter, iter_counter, loss_hist, test_loss_hist, test_data, test_targets):\n",
    "    print(f'Epoch {epoch}, Iteration {iter_counter}')\n",
    "    print(f'Train Set Loss: {loss_hist[counter]:.2f}')\n",
    "    print(f'Test Set Loss: {test_loss_hist[counter]:.2f}')\n",
    "    print_batch_accuracy(data, targets, train=True)\n",
    "    print_batch_accuracy(test_data, test_targets, train=False)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e62519",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m loss = \u001b[43mnn\u001b[49m.CrossEntropyLoss()\n",
      "\u001b[31mNameError\u001b[39m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5f76c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=5e-4, betas=(0.9, 0.999))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "st",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
